#LLM_TYPE will take openai, local. Local will use Ollama
LLM_TYPE = 'openai' 

#-----OpenAI variables
OPENAI_API_KEY = ''
OPENAI_MODEL = 'gpt-4o-mini'

#-----Ollama variables
#OLLAMA_MODEL will take any model you can load in ollama
OLLAMA_MODEL = 'gemma2' 
OLLAMA_URL = 'http://localhost:11434' 

#-----Customization Variables
#CHARACTER will take any character prompt you have in the prompts/prompts.py file. 'bob' is the default character with no special prompt. If you change the character you will need to add a prompt for that character in the prompts.py file
CHARACTER = 'bob'
#If you want this to listen and attempt to translate all text you can disable wake word. However, speech to text transcription can sometimes return incorrect results when there is background noise. Set to false to disable wake word. When enabled the wake phrase will be wake word + character name, for example "hey max"
WAKE_WORD_ENABLED = 'True'
WAKE_WORD = 'hey'

#LISTEN_MODEL will take whisper or google, whisper is the best option but requires additional setup with Nvidia drivers
LISTEN_MODEL = 'google'
#TIME_SILENCE is how long the silence needs to be after voice for it to stop listening and transcribe. This speeds up the process, sending messages, and adjusting for noise.
TIME_SILENCE = '2'

#If you are using whisper and you have an nvidia GPU, AND you have followed the additional installation steps to get the CUDA drivers, then set the following to True to use the Nvidia card
WHISPER_NVIDIA = 'False'

#SPEECH_ENABLED is enabled by default and is what sets the LLM to speak back. Disable if you want it to only print its response
SPEECH_ENABLED = 'True'

#STREAM SPEAK URL is using the default url for Alltalk. If you dont have all talk you can ignore this, if you want to use a different service, simply replace the url
STREAM_SPEAK_URL = 'http://127.0.0.1:7851/api/tts-generate'
ALL_TALK_VOICE = 'male_01.wav'






